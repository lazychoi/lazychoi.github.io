{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cb4a5603-9338-447e-8c7b-d9cffb50f5c8",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"이토록 쉬운 머신러닝&딥러닝 입문 3장 파이토치를 활용한 딥러닝\"\n",
    "date: 2022/11/17\n",
    "date-modified: last-modified\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e48a07-e1a4-40cb-9527-ee0fecef22d1",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "## 시그모이드 함수 사용 이유\n",
    "\n",
    "단위 계단 함수(unit step function)은 불연속이므로 미분할 수 없는 지점이 있어 퍼셉트론 학습에 사용하기에 적합하지 않다. 0과 1 사의의 연속적인 값을 가지는 시그모이드(sigmoid) 함수를 사용한다. p214\n",
    ":::\n",
    "\n",
    ":::{.callout-important}\n",
    "다층 퍼셉트론(multi-layer perceptron)에서는 입력 데이터도 하나의 층으로 간주한다. p217\n",
    ":::\n",
    "\n",
    ":::{.callout-important}\n",
    "## 오차 역전파\n",
    "\n",
    "오차 역전파(back-propagation)는 출력층에서 입력층 방향으로 뒤에서부터 오차를 추적하며 경사 하강법을 이용해 가중치와 편향을 수정하는 수학적 방법이다. 오차 역전파의 수학적 원리는 연쇄 법칙(chain rule)과 편미분(partial derivative)이다. 신경망은 구조가 복잡해서 손실 함수의 기울기를 계산하고 경사 하강법으로 가중치와 편향을 수정하는 과정의 연산량이 많기 때문에 이 연산 과정을 수학적으로 개선한 방법이 오차 역전파다. p218\n",
    "::: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b2d2d-4fa6-4e84-988c-ff48df188722",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "## 기울기 소실(gradient vanishing) 문제\n",
    "\n",
    "오차 역전파의 계산 과정에서 층마다 활성화 함수의 기울기를 곱하는데, 활성화 함수로 사용하는 시그모이드 함수의 기울기는 0.3 미만이다. 따라서 은닉층을 지날 때마다 0.3 미만의 값을 반복해서 곱하다 보면 입력층에 가까워졌을 때는 기울기가 0에 가까워진다. 가중치를 수정할 때는 기울기의 크기에 학습률을 곱한 만큼 가중치를 수정하게 되는데, 기울기가 0에 가까우면 기울기의 크기에 학습률은 곱한 결과도 0에 가까우므로 가중치가 거의 수정되지 않아 제대로 학습이 되지 않는다. 이를 해결하기 위해 은닉층 활성화 함수로 시그모이드 함수 대신 렐루 함수를 사용한다. 렐루 함수는 값이 0을 넘을 때는 미분 값이 항상 1이기 때문에 많은 은닉층이 있어도 기울기가 소실되지 않고 잘 전달된다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89053918-f485-4b55-a3d1-54ea0a1d7dd1",
   "metadata": {},
   "source": [
    "## 활성화 함수\n",
    "\n",
    "| 사용층 | 용도 | 활성화 함수 | <span style=\"display: inline-block; width:400px\">설명</span> |\n",
    "|:-:|:-:|:-:|-|\n",
    "|은닉층| 기울기 소실 문제를 줄이고 다음 층으로 신호 전달 | 렐루 / 리키 렐루 | 0이하는 모두 0, 0 초과는 항상 1 |\n",
    "|출력층| 이진 분류 | 시그모이드 | 양성일 확률로 따져 양성, 음성 판정 |\n",
    "| | 다중 분류 | 소프트맥스 | 각 클래스에 속할 확률을 따져 분류 |\n",
    "| | 회귀 | - | 노드 값을 그대로 출력 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8bff1-5841-4d5e-843d-465eb0bf9c60",
   "metadata": {},
   "source": [
    "## 손실 함수\n",
    "\n",
    "| 용도 | 손실 함수 |\n",
    "|:-:|-|\n",
    "| 이진 분류 | 이진 크로스 엔트로피 |\n",
    "| 다중 분류 | 크로스 엔트로피 |\n",
    "| 회귀 | 평균 제곱 오차|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f57c67-ef9a-4ea4-bd85-db71517fe3f8",
   "metadata": {},
   "source": [
    "## 옵티마이저(optimizer) - 사용하는 경사 하강법 종류\n",
    "\n",
    "| 옵티마이저 | 특징 |\n",
    "|-|-|\n",
    "| 확률적 경사 하강법(SGD, Stochastic Gradient Descent) | 데이터 샘플을 무작위로 추출하여 일부만 경사 하강법을 사용해 학습 속도 개선|\n",
    "| RMSProp(Root Mean Square Propagation) | 학습률이 커서 최적 가중치를 지나치는 문제 해결<br>손실 함수의 기울기가 크면 학습률이 크고 작으면 학습률이 작아지도록 조절 |\n",
    "| 모멘텀(momentum) | 지역 최솟값에 갇히는 문제를 해결하기 위해<br>손실 함수의 기울기가 0인 여러 지점 중 한 지점에서 멈추지 않고<br>계속 최솟값을 찾도록 관성 개념을 추가 |\n",
    "| 아담(adam) | RMSProp과 모멘텀 기능을 합침 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2b9ea-091c-4c24-adbb-e0b034138513",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "## 텐서(tensor) 자료구조\n",
    "\n",
    "넘파이 배열과 구조적, 기능적으로 거의 비슷하지만 그래픽 카드를 사용해 병렬 연산을 할 수 있다는 차이가 있다. NVIDIA 그래픽 카드가 제공하는 쿠다(cuda) 환경에서 모델을 학습할 수 있다. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80619c1d-b84b-4ca2-82ba-19a16a5b32d7",
   "metadata": {},
   "source": [
    "## 선형 회귀 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef6df8d-4a21-40ba-81da-f7ff8794b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim # 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811be2c9-39c7-45d7-8421-030233563f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_boston()\n",
    "\n",
    "X, y = dataset['data'], dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc676925-af1d-4f53-ab66-7b2f0ccd0648",
   "metadata": {},
   "source": [
    "### 특성과 타깃을 텐서 자료구조로 변환\n",
    "\n",
    "- 실수형 텐서: torch.FloatTensor\n",
    "- 정수형 텐서: torch.LongTensor\n",
    "- 파이토치는 **타겟을 2차원 배열로 설정**해야 한다.\n",
    "- 차원 추가 메서드 : unsqueeze() eg. 맨 뒤에 길이가 1인 차원 추가 unsqueeze(-1)\n",
    "- 차원 제거 메서드 : squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d40cab8-d0f8-4eab-8e8a-083a523c0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e88590-31cb-4db5-9e90-1c52cc6007d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([506, 13]), torch.Size([506, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a7abc-61ce-451f-94f6-6d5582285340",
   "metadata": {},
   "source": [
    "### 표준화\n",
    "\n",
    "sklearn의 StandardSacler는 2차원 배열까지만 지원하기 때문에 3차원 이상의 데이터를 많이 다루는 딥러닝에서는 표준화를 직접 하는 것에 익숙해져야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d49f7f-0b82-43dc-b7b2-94f6e9ca7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - torch.mean(X))/torch.std(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730735d-eabb-4b3f-a579-0fb0388cf0dd",
   "metadata": {},
   "source": [
    "### 선형 회귀 모델 객체 생성\n",
    "\n",
    "(입력값, 출력값) = (특성 13개, 타겟 1개)\n",
    "\n",
    "- 활성화 함수 => 시그모이드 함수 => 로지스틱 회귀\n",
    "- 활성화 함수 없는 퍼셉트론 => 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "babb7c4a-b244-49c0-a108-f7aa3528bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(13, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8e7fa-969e-4b19-98db-1e3cac119692",
   "metadata": {},
   "source": [
    "### 손실함수와 옵티마이저 객체 생성\n",
    "\n",
    "- MSE 손실 함수 -> criterion 변수 이름이 관례\n",
    "- 확률적 경사 하강법 옵티마이저 \n",
    "- parameters 메서드로 모델의 가중치를 불러올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3c9484-3a98-4369-8117-030c117b9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca304a-8517-4f8d-8b73-41d6d79e88db",
   "metadata": {},
   "source": [
    "### 학습 함수 정의(에포크 1회) -> 오차(손실) 반환\n",
    "\n",
    "1. 손실 함수로 오차 계산(실제 타깃과 모델 예측 타깃의 차이)\n",
    "1. 미분으로 손실 함수 기울기 계산하여 가중치를 어떻게 수정해야 오차가 줄어드는지 파악\n",
    "1. 학습률만큼 가중치 수정\n",
    "\n",
    "한 번의 에포크는 주어진 모든 데이터 샘플을 이용해 한 번 학습하는 것을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d4d407a-485c-43e2-aacc-055cc343f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, X, y):\n",
    "    \n",
    "    optimizer.zero_grad()           # 기울기 초기화\n",
    "    hypothesis = model(X)           # 모델 사용해 타깃 예측\n",
    "    loss = criterion(hypothesis, y) # 오차 계산\n",
    "    loss.backward()                 # 기울기 계산\n",
    "    optimizer.step()                # 경사하강법으로 가중치 수정\n",
    "    return loss.item()              # 현재 에포크 오차 반환 -> 파이썬 숫자형 자료구조로 변환(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea30fb-5c95-4892-a0eb-011719a80278",
   "metadata": {},
   "source": [
    "### 학습하며 오차 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6c13528-aa2c-4536-822a-708ca362b498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 115.4186\n",
      "epoch: 20, loss: 97.9571\n",
      "epoch: 30, loss: 88.5269\n",
      "epoch: 40, loss: 82.5146\n",
      "epoch: 50, loss: 78.6239\n",
      "epoch: 60, loss: 76.0548\n",
      "epoch: 70, loss: 74.3105\n",
      "epoch: 80, loss: 73.0827\n",
      "epoch: 90, loss: 72.1799\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100 # 학습 횟수\n",
    "for epoch in range(1, n_epochs):\n",
    "    loss = train(model, criterion, optimizer, X, y)\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}, loss: {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ec3fe-1e45-4bfe-bd02-9145cfa8c8a4",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀\n",
    "\n",
    "- 이진 크로스 엔트로피 손실 함수 사용\n",
    "- view 메서드는 넘파이의 reshape와 유사\n",
    "\n",
    "### 데이터 불러오기, 텐서 변환, 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66617dc0-5c06-43c7-8ddb-213cd66c1752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([569, 30]), torch.Size([569, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = dataset['data'], dataset['target']\n",
    "\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).view(-1, 1)\n",
    "\n",
    "X = (X - torch.mean(X)) / torch.std(X)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4c3f4-207a-4072-b288-47546b752125",
   "metadata": {},
   "source": [
    "### nn.Sequential\n",
    "\n",
    "Sequential 클래스 생성자에 모델 객체와 활성화 함수 객체를 전달하면 두 객체를 차례대로 사용해 계산한 결과를 반환하는 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c04b3b9b-e7e0-4932-8052-8d4452e8c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(30, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b5fd0-354a-4846-a4cb-e248b2277cd7",
   "metadata": {},
   "source": [
    "### 손실함수, 옵티마이저 정의 / 학습 함수 정의 / 학습\n",
    "\n",
    "이진 크로스 엔트로피(Binary Cross Entropy) 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e88d49d3-223f-4a72-92bd-33085a032417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.6046\n",
      "epoch: 20, loss: 0.5323\n",
      "epoch: 30, loss: 0.4806\n",
      "epoch: 40, loss: 0.4422\n",
      "epoch: 50, loss: 0.4126\n",
      "epoch: 60, loss: 0.3891\n",
      "epoch: 70, loss: 0.3701\n",
      "epoch: 80, loss: 0.3543\n",
      "epoch: 90, loss: 0.3411\n",
      "epoch: 100, loss: 0.3298\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def train(model, criterion, optimizer, X, y):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    loss = criterion(hypothesis, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(model, criterion, optimizer, X, y)\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}, loss: {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aba859-c635-40a0-9598-b320de01da0c",
   "metadata": {},
   "source": [
    "### 타깃 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "570bb5b4-5120-473a-a469-f94f867610c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 518.00\n"
     ]
    }
   ],
   "source": [
    "y_predicted = (model(X) >= 0.5).float()\n",
    "\n",
    "score = (y_predicted == y).float().sum()\n",
    "print('accuracy: {:.2f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a8f8c-a74c-4201-b176-1a15d85158fb",
   "metadata": {},
   "source": [
    "## 클래스로 모델 정의\n",
    "\n",
    "- 파이토치에서 모델 클래스를 정의할 때는 nn.Module 클래스를 상속받아야 한다.\n",
    "- 모델 구조는 `__init__` 생성자 안에 정의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5c922-e14d-40e8-a9c2-29f0e06537b6",
   "metadata": {},
   "source": [
    "### 선형회귀 모델 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3796a6b6-0279-4695-88fe-28514a74ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, num_features): # 생성자에서 모델 구조 정의\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "    \n",
    "    def forward(self, X): # 순전파 정의\n",
    "        out = self.linear(X)  # 생성자에서 만든 선형모델로 타깃 예측 및 반환\n",
    "        return out\n",
    "    \n",
    "model = LinearRegression(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fdbe6-dcb2-492c-a84f-8909e2e9004b",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀 모델 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7d45d67-6203-4703-83be-e59b97f7dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.linear(X)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "model = LogisticRegression(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48904531-d595-4d27-a09c-9357d4220927",
   "metadata": {},
   "source": [
    "## 배치(batch) 학습\n",
    "\n",
    "전체 데이터에 대한 추론과 오차 역전파를 한 번에 실행하기에는 컴퓨터 메모리 한계가 존재한다. 이 문제를 해결하기 위해 데이터를 나눠서 처리하는 배치라는 개념이 등장한다. 배치란 한 번의 에포크를 수행할 때 처리하는 샘플의 개수를 의미한다. 전체 데이터 샘플을 지정된 배치 크기로 나눠서 학습하고 마지막 배치 학습이 끝나면 한 번의 에포크가 수행된 것이다.\n",
    "\n",
    "배치 학습을 위해 DataLoader 클래스 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683c7edd-56fe-47dd-93fd-eb6710304060",
   "metadata": {},
   "source": [
    "### 데이터 로드, 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b370184-f4fa-4049-afe3-c54bb7c28896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "X, y = dataset['data'], dataset['target']\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).view(-1,1)\n",
    "\n",
    "X = (X - torch.mean(X)) / torch.std(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22e9b9-94b7-4887-9211-ff7a57faf741",
   "metadata": {},
   "source": [
    "### 배치 학습 구현 위해 데이터와 타깃 합치기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a08f83b-f979-4355-a5cc-0581200daf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터와 타깃을 묶어 텐서 데이터셋 생성\n",
    "dset = TensorDataset(X, y)\n",
    "\n",
    "# 한 번에 256개의 데이터 샘플을 배치로 사용하는 데이터로더 생성\n",
    "loader = DataLoader(dset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a0600-f3e6-4869-a177-73b80a828297",
   "metadata": {},
   "source": [
    "### 신경망 모델 클래스 정의 / 학습 함수 정의 / 학습 / 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67a0771b-3893-4fa9-8c05-1bed31464e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.5338\n",
      "epoch: 20, loss: 0.3442\n",
      "epoch: 30, loss: 0.2628\n",
      "epoch: 40, loss: 0.2579\n",
      "epoch: 50, loss: 0.2114\n",
      "epoch: 60, loss: 0.1996\n",
      "epoch: 70, loss: 0.2114\n",
      "epoch: 80, loss: 0.2221\n",
      "epoch: 90, loss: 0.2065\n",
      "epoch: 100, loss: 0.2161\n",
      "accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_features, 4) # 은닉층 노드 4개 생성\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.linear1(X)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork(30) \n",
    "criterion = nn.BCELoss()  # 이진 크로스 엔트로피\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train(model, criterion, optimizer, loader):\n",
    "    epoch_loss = 0    # 현재 에포크의 오차 저장 변수\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() # 현재 배치의 오차 누적\n",
    "        \n",
    "    return epoch_loss / len(loader) # 현대 에포크의 오차 평균 반환\n",
    "\n",
    "# 모델 학습\n",
    "n_epochs = 100\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(model, criterion, optimizer, loader)\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}, loss: {:.4f}'.format(epoch, loss))\n",
    "        \n",
    "# 학습된 모델로 타깃 예측\n",
    "y_predicted = (model(X) >= 0.5).float()\n",
    "\n",
    "# 정확도 계산\n",
    "score_trained_model = (y_predicted == y).float().mean()\n",
    "print('accuracy: {:.2f}'.format(score_trained_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f421031-c8c1-43ba-a000-47d410a5edc3",
   "metadata": {},
   "source": [
    "### 모델 저장\n",
    "\n",
    "- model.state_dict() 모델 정보를 가진 딕셔너리에 접근\n",
    "- torch.save() 모델 저장 .pt 또는 .pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b788f8de-f15b-4084-a2d2-cae3005ca86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'breast_cancer.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83805b2-4715-49ed-a129-3c02cb66707d",
   "metadata": {},
   "source": [
    "### 모델 로드, 예측\n",
    "\n",
    "- torch.load() 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "698ba073-50b7-404e-92b4-35e4e794bff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of loaded model: 0.92\n"
     ]
    }
   ],
   "source": [
    "# 신경망 모델의 객체 생성\n",
    "loaded_model = NeuralNetwork(30)\n",
    "\n",
    "# 저장한 파일에서 가중치 불러와 복원\n",
    "loaded_model.load_state_dict(torch.load('breast_cancer.pt'))\n",
    "\n",
    "# 타깃 예측\n",
    "y_pred2 = (loaded_model(X) >= 0.5).float()\n",
    "\n",
    "score_loaded_model = (y_pred2 == y).float().mean()\n",
    "print('accuracy of loaded model: {:.2f}'.format(score_loaded_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d9b518-0c1a-4f7d-9cf5-eea4d225cc4c",
   "metadata": {},
   "source": [
    "## 심층 신경망(DNN) = 전결합(fully connected) 신경망\n",
    "\n",
    "전결합층(fully connected layer) : 이전 층의 모든 노드와 연결된 노드로 구성된 은닉층 또는 츨력층\n",
    "\n",
    ":::{.callout-important}\n",
    "DNN은 1차원 배열을 입력으로 받는다.\n",
    ":::\n",
    "\n",
    "### 손글씨 이미지 분류\n",
    "\n",
    "MNIST datasets는 torchvision 라이브러리에 내장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b9df9-61c1-4d4e-9002-5f901e64b29d",
   "metadata": {},
   "source": [
    "#### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "227124cb-cab1-4ec2-954e-f79caa333738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a5fd350e9240e1bfd136ec996ea606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e854eeed69ed440bb0e8f359314785f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74adf86bf40b4777a6f9b0bec96b3673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c97c59106e641ae8daa499966857e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 현재 경로에 MNIST 학습 세트와 테스트 세트 불러오기\n",
    "path = './'\n",
    "train_dataset = datasets.MNIST(path, train=True, download=True)\n",
    "test_dataset = datasets.MNIST(path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9285250-f66e-4579-8083-24a98cfa771e",
   "metadata": {},
   "source": [
    "#### 입력 데이터를 1차원으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca0cf4df-8e43-4f49-8b16-7f5411fdd269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 입력 데이터: torch.Size([60000, 28, 28])\n",
      "학습 세트 타겟: torch.Size([60000])\n",
      "테스트 세트 입력 데이터: torch.Size([10000, 28, 28])\n",
      "테스트 세트 타겟: torch.Size([10000])\n",
      "\n",
      "학습 세트 입력 데이터: torch.Size([60000, 784])\n",
      "테스트 세트 입력 데이터: torch.Size([10000, 784])\n",
      "epoch: 100, loss: 0.548, acc: 0.86, test_loss: 0.276, test_acc: 0.922\n",
      "epoch: 100, loss: 0.254, acc: 0.93, test_loss: 0.215, test_acc: 0.938\n",
      "epoch: 100, loss: 0.203, acc: 0.94, test_loss: 0.182, test_acc: 0.947\n",
      "epoch: 100, loss: 0.169, acc: 0.95, test_loss: 0.159, test_acc: 0.953\n",
      "epoch: 100, loss: 0.143, acc: 0.96, test_loss: 0.138, test_acc: 0.959\n",
      "epoch: 100, loss: 0.123, acc: 0.96, test_loss: 0.120, test_acc: 0.964\n",
      "epoch: 100, loss: 0.106, acc: 0.97, test_loss: 0.108, test_acc: 0.967\n",
      "epoch: 100, loss: 0.093, acc: 0.97, test_loss: 0.103, test_acc: 0.969\n",
      "epoch: 100, loss: 0.081, acc: 0.98, test_loss: 0.095, test_acc: 0.971\n",
      "epoch: 100, loss: 0.071, acc: 0.98, test_loss: 0.086, test_acc: 0.975\n",
      "epoch: 100, loss: 0.063, acc: 0.98, test_loss: 0.082, test_acc: 0.975\n",
      "epoch: 100, loss: 0.056, acc: 0.98, test_loss: 0.082, test_acc: 0.976\n",
      "epoch: 100, loss: 0.049, acc: 0.99, test_loss: 0.078, test_acc: 0.977\n",
      "epoch: 100, loss: 0.044, acc: 0.99, test_loss: 0.075, test_acc: 0.977\n",
      "epoch: 100, loss: 0.039, acc: 0.99, test_loss: 0.075, test_acc: 0.977\n",
      "epoch: 100, loss: 0.035, acc: 0.99, test_loss: 0.072, test_acc: 0.978\n",
      "epoch: 100, loss: 0.031, acc: 0.99, test_loss: 0.072, test_acc: 0.977\n",
      "epoch: 100, loss: 0.027, acc: 0.99, test_loss: 0.073, test_acc: 0.978\n",
      "epoch: 100, loss: 0.024, acc: 0.99, test_loss: 0.068, test_acc: 0.979\n",
      "epoch: 100, loss: 0.021, acc: 1.00, test_loss: 0.070, test_acc: 0.978\n"
     ]
    }
   ],
   "source": [
    "# X, y로 나누고 정규화. 0~255 사이의 흑백이미지 -> 0~1 사이의 실수값\n",
    "# 정규화를 하면 오파를 줄이기 위한 에포크 반복 횟수를 줄일 수 있다.\n",
    "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
    "X_test, y_test = test_dataset.data / 255, test_dataset.targets\n",
    "\n",
    "# train, test 데이터 형태 확인\n",
    "# 학습 6만 개, 테스트 만 개\n",
    "print('학습 세트 입력 데이터:', X_train.shape)\n",
    "print('학습 세트 타겟:', y_train.shape)\n",
    "print('테스트 세트 입력 데이터:', X_test.shape)\n",
    "print('테스트 세트 타겟:', y_test.shape)\n",
    "print()\n",
    "\n",
    "#########################################################################\n",
    "# 전결합층은 1차원 벡터를 입력값으로 받기 때문에 1차원 배열로 변환. 이미지 크기 28*28 = 784\n",
    "#########################################################################\n",
    "X_train, X_test = X_train.view(-1, 784), X_test.view(-1, 784)\n",
    "print('학습 세트 입력 데이터:', X_train.shape)\n",
    "print('테스트 세트 입력 데이터:', X_test.shape)\n",
    "\n",
    "################################################\n",
    "# 배치 학습 위해 입력 데이터와 타깃을 묶어 텐서데이터세트 생성\n",
    "################################################\n",
    "train_dset = TensorDataset(X_train, y_train)\n",
    "test_dset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# 한 번에 32개의 데이터 샘플을 배치로 사용하는 데이터로더 생성\n",
    "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dset, batch_size=32, shuffle=True)\n",
    "\n",
    "######################\n",
    "# DNN 모델 클래스 정의\n",
    "######################\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "\n",
    "        # 첫 번째 은닉층\n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 두 번째 은닉층\n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 출력층 정의 : 0부터 9까지 숫자를 구분 -> 노드 개수 10\n",
    "        # 다중 분류는 출력층에 softmax 함수를 사용하지만 \n",
    "        # 사용할 크로스 엔트로피 손살 함수에 소프트맥스 연산이 내장되어 있어 생략\n",
    "        self.output_layer = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.hidden_layer1(X)\n",
    "        out = self.hidden_layer2(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "    \n",
    "##############################\n",
    "# 그래픽카드 사용 가능할 경우 이용한다.\n",
    "##############################\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 784개 값을 입력받는 로지스틱 회귀 모델 객체 생성\n",
    "# 모델 객체와 데이터세트틑 to 메서드를 이용해 어떤 장치에서 연산할지 선택\n",
    "model = DNN(784).to(device)\n",
    "\n",
    "# 손실함수와 옵티마이저 객체 생성\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "##############\n",
    "# 학습 함수 정의\n",
    "##############\n",
    "def train(model, criterion, optimizer, loader):\n",
    "    '''현대 에포크의 손실(오차)과 정확도 반환'''\n",
    "    \n",
    "    epoch_loss = 0 # 현재 에포크 오차\n",
    "    epoch_acc = 0  # 현재 에포크 정확도\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward() # 기울기 계산\n",
    "        optimizer.step() # 가중치 수정\n",
    "        y_predicted = torch.argmax(hypothesis, 1) # torch.argmax(input, dim)\n",
    "        acc = (y_predicted == y_batch).float().mean() # 정확도\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "##############################\n",
    "# 평가 함수 정의 - test data 사용\n",
    "##############################\n",
    "def evaluate(model, criterion, loader):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    with torch.no_grad(): # 오차 역전파가 사용되지 않도록 파이토치가 연산 내역을 추적하지 않게 한다\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            hypothesis = model(X_batch)\n",
    "            loss = criterion(hypothesis, y_batch)\n",
    "            y_predicted = torch.argmax(hypothesis, 1)\n",
    "            acc = (y_predicted == y_batch).float().mean()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "###############\n",
    "# 20회 학습 실행\n",
    "###############\n",
    "n_epochs = 20\n",
    "for eppoch in range(1, n_epochs+1):\n",
    "    \n",
    "    # 모델 학습\n",
    "    loss, acc = train(model, criterion, optimizer, train_loader)\n",
    "    \n",
    "    # 모델 평가\n",
    "    test_loss, test_acc = evaluate(model, criterion, test_loader)\n",
    "    \n",
    "    print('epoch: {}, loss: {:.3f}, acc: {:.2f}, test_loss: {:.3f}, test_acc: {:.3f}'.format(epoch, loss, acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8fe174-5c66-4147-a435-5e36b401fd64",
   "metadata": {},
   "source": [
    "### 과적합 줄이기 - dropout\n",
    "\n",
    "- 가중치 수가 아주 많으면 학습 세트의 입력 데이터와 타겟을 완벽하게 매핑하도록 가중치를 학습 -> 일반화 오류 가능성 커짐\n",
    "- 가중치 수가 적으면 많은 양의 정보를 저장할 수 없으므로 전체 데이터 샘플의 일반적 특징을 학습\n",
    "- 따라서, 과적합을 줄이고 일반화를 높이려면 가중치 수를 줄여 모델을 단순하게 만들면 된다.\n",
    "- 은닉층 또는 은닉층의 노드 수를 수정하거나 조기 종료\n",
    "- 드롭아웃(dropout) : 무작위로 일부 노드를 누락시켜 특정 정보만으로 결론을 도출하지 못하도록 규제하는 학습 방법이다. eg. 머리 짧은 남자와 머리 긴 여자 사진만 학습하면 머리가 길면 무조건 여자로 판단할 수 있어, 드롭아웃을 적용하면 사진의 일부로 조금씩 가려 학습시킨다. \n",
    "- 드롭아웃은 매번 지정된 비율만큼의 노드를 무작위로 누락시켜 값을 0으로 만든다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b8a9b-7b04-4417-8e17-9f3a4d6e0225",
   "metadata": {},
   "source": [
    "## CNN(Convolutional Neural Network, 합성곱 신경망)\n",
    "\n",
    "- 컴퓨터 비전 문제에서 머신러닝에 비해 좋은 성능을 보여줌\n",
    "- 이미지를 여러 조각으로 쪼개 지역적인 특징 추출\n",
    "- 출력층은 전결합층을 사용하는 경우 많음\n",
    "- 보통 입력 데이터보다 작은 크기의 필터를 입력 데이터 영역에서 이동시키며 특성 맵(feature map)이라고 하는 값은 계산함. 필터의 크기가 클수록 데이터 영역에서 움직이는 횟수가 적어 특성 맵 크기는 작아진다.\n",
    "- 하나의 합성곱층에서 여러 개의 필터를 사용해 여러 개의 특성맵을 생성하는데, 각각의 특성맵은 이미지의 모서리나 질감 등 다양한 특징을 발견한다.\n",
    "- 합성곱층을 여러 겹 쌓을수록 고수준의 특징을 감지하는 특성 맵을 만들 수 있다. 초반에는 모서리나 질감 같은 저수준의 특징을 잡아내고 이후 층으로 갈수록 저수준의 특징을 이용해 눈, 코, 입 같은 고수준의 특징을 감지한다.\n",
    "\n",
    "### CNN 활용한 손글씨 이미지 분류\n",
    "\n",
    ":::{.callout-important}\n",
    "합성곱 신경망은 **채널, 높이, 너비 순서로 3차원 배열을 입력**으로 받는다.\n",
    ":::\n",
    "\n",
    "MNIST 데이터세트는 흑백 이미지이므로 채널이 한 개이지만, 실제로는 채널을 생략하고 높이와 너비만으로 구성된 2차원 데이터이다. 따라서 unsqueeze 메서드로 높이 차원 앞에 채널 차원을 추가하여 3차원으로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c1b5ceb-5262-4ccd-8260-27b83f0d0e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features: torch.Size([60000, 28, 28])\n",
      "train target: torch.Size([60000])\n",
      "test fearues: torch.Size([10000, 28, 28])\n",
      "test target: torch.Size([10000])\n",
      "\n",
      "train features: torch.Size([60000, 1, 28, 28])\n",
      "test features: torch.Size([10000, 1, 28, 28])\n",
      "epoch: 1, loss: 0.427, acc: 0.87, test_loss: 0.127, test_acc: 0.963\n",
      "epoch: 2, loss: 0.138, acc: 0.96, test_loss: 0.072, test_acc: 0.978\n",
      "epoch: 3, loss: 0.101, acc: 0.97, test_loss: 0.057, test_acc: 0.982\n",
      "epoch: 4, loss: 0.086, acc: 0.97, test_loss: 0.046, test_acc: 0.985\n",
      "epoch: 5, loss: 0.076, acc: 0.98, test_loss: 0.042, test_acc: 0.987\n",
      "epoch: 6, loss: 0.069, acc: 0.98, test_loss: 0.040, test_acc: 0.987\n",
      "epoch: 7, loss: 0.064, acc: 0.98, test_loss: 0.036, test_acc: 0.989\n",
      "epoch: 8, loss: 0.060, acc: 0.98, test_loss: 0.035, test_acc: 0.989\n",
      "epoch: 9, loss: 0.058, acc: 0.98, test_loss: 0.033, test_acc: 0.989\n",
      "epoch: 10, loss: 0.053, acc: 0.98, test_loss: 0.034, test_acc: 0.989\n",
      "epoch: 11, loss: 0.052, acc: 0.98, test_loss: 0.030, test_acc: 0.990\n",
      "epoch: 12, loss: 0.048, acc: 0.99, test_loss: 0.031, test_acc: 0.990\n",
      "epoch: 13, loss: 0.046, acc: 0.99, test_loss: 0.029, test_acc: 0.991\n",
      "epoch: 14, loss: 0.045, acc: 0.99, test_loss: 0.030, test_acc: 0.991\n",
      "epoch: 15, loss: 0.044, acc: 0.99, test_loss: 0.029, test_acc: 0.991\n",
      "epoch: 16, loss: 0.041, acc: 0.99, test_loss: 0.027, test_acc: 0.991\n",
      "epoch: 17, loss: 0.041, acc: 0.99, test_loss: 0.026, test_acc: 0.991\n",
      "epoch: 18, loss: 0.038, acc: 0.99, test_loss: 0.024, test_acc: 0.993\n",
      "epoch: 19, loss: 0.036, acc: 0.99, test_loss: 0.028, test_acc: 0.990\n",
      "epoch: 20, loss: 0.037, acc: 0.99, test_loss: 0.024, test_acc: 0.991\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 현재 경로에 MNIST 학습 세트와 테스트 세트 불러오기\n",
    "path = './'\n",
    "train_dataset = datasets.MNIST(path, train=True, download=True)\n",
    "test_dataset = datasets.MNIST(path, train=False, download=True)\n",
    "\n",
    "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
    "X_test, y_test = test_dataset.data / 255, test_dataset.targets\n",
    "\n",
    "print('train features:', X_train.shape)\n",
    "print('train target:', y_train.shape)\n",
    "print('test fearues:', X_test.shape)\n",
    "print('test target:', y_test.shape)\n",
    "\n",
    "############################\n",
    "# 채널을 추가하여 3차원 배열로 변환\n",
    "############################\n",
    "X_train, X_test = X_train.unsqueeze(1), X_test.unsqueeze(1)\n",
    "print('\\ntrain features:', X_train.shape)\n",
    "print('test features:', X_test.shape)\n",
    "\n",
    "# 배치 \n",
    "train_dset = TensorDataset(X_train, y_train)\n",
    "test_dset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dset, batch_size=32, shuffle=True)\n",
    "\n",
    "####################\n",
    "# CNN 모델 클래스 정의\n",
    "####################\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 합성곱 은닉층\n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(3,3)), # Conv2d(채널수, 필터수) -> 64개 특성맵 생성\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)), # 최대 풀링 -> 학습되는 가중치 없음\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # 합성곱 은닉층\n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # 전결층 -> 1차원으로 변환\n",
    "        self.hidden_layer3 = nn.Linear(128*5*5, 128) # 이전 은닉층에서 높이 5, 너비 5인 특성 맵 128개 생성\n",
    "        nn.ReLU()\n",
    "        \n",
    "        # 출력층 -> 최종 분류는 10개\n",
    "        self.output_layer = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.hidden_layer1(X)\n",
    "        out = self.hidden_layer2(out)\n",
    "        out = out.view(out.shape[0], -1) # 전결층 -> 1차원으로 변환\n",
    "        out = self.hidden_layer3(out)\n",
    "        out = self.output_layer(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "# 그래픽 카드 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 합성곱 신경망 모델 객체 생성\n",
    "model = CNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train(model, criterion, optimizer, loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train() # 모델을 학습 모드로 설정\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_predicted = torch.argmax(hypothesis, 1)\n",
    "        acc = (y_predicted == y_batch).float().mean()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "    \n",
    "# 평가 함수 정의\n",
    "def evaluate(model, criterion, loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval() # 모델을 평가 모드로 설정\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            hypothesis = model(X_batch)\n",
    "            loss = criterion(hypothesis, y_batch)\n",
    "            y_predicted = torch.argmax(hypothesis, 1)\n",
    "            acc = (y_predicted == y_batch).float().mean()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "        return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "    \n",
    "# 모델 학습\n",
    "n_epochs = 20\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss, acc = train(model, criterion, optimizer, train_loader)\n",
    "    test_loss, test_acc = evaluate(model, criterion, test_loader)\n",
    "    \n",
    "    print('epoch: {}, loss: {:.3f}, acc: {:.3f}, test_loss: {:.3f}, test_acc: {:.3f}'.format(epoch, loss, acc, test_loss, test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354981c6-747a-48b0-bb25-c32a67048be5",
   "metadata": {},
   "source": [
    "### 가중치 수 계산\n",
    "\n",
    "torchsummary.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b417bdb1-8e49-41ff-81ad-abbafa8067e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 26, 26]             640\n",
      "              ReLU-2           [-1, 64, 26, 26]               0\n",
      "         MaxPool2d-3           [-1, 64, 13, 13]               0\n",
      "           Dropout-4           [-1, 64, 13, 13]               0\n",
      "            Conv2d-5          [-1, 128, 11, 11]          73,856\n",
      "              ReLU-6          [-1, 128, 11, 11]               0\n",
      "         MaxPool2d-7            [-1, 128, 5, 5]               0\n",
      "           Dropout-8            [-1, 128, 5, 5]               0\n",
      "            Linear-9                  [-1, 128]         409,728\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 485,514\n",
      "Trainable params: 485,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.11\n",
      "Params size (MB): 1.85\n",
      "Estimated Total Size (MB): 2.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17e768-ea88-4702-ac0c-d1a812477365",
   "metadata": {},
   "source": [
    "### shape 계산\n",
    "\n",
    "1. Conv2d 후 특성 맵 shape 계산\n",
    "\n",
    "$\\text{특성맵의 행 크기} = \\frac{\\text{입력 데이터의 행 크기} - \\text{필터의 행 크기}}{stride} + 1$\n",
    "\n",
    "$\\text{특성맵의 열 크기} = \\frac{\\text{입력 데이터의 열 크기} - \\text{필터의 열 크기}}{stride} + 1$\n",
    "\n",
    "- 입력(1, 28, 28) 채널 1개, 높이 28, 넓이 28, 필터(64개, 3, 3)\n",
    "- stride는 조건이 없으니 1로 가정\n",
    "- (28 - 3) + 1 => 26 \n",
    "- 따라서 (64, 26, 26) 26x26 크기의 특성 맵이 64개\n",
    "\n",
    "2. ReLU 활성화 함수에서 학습되는 가중치는 없고 데이터 형태에도 영향을 주지 않는다.\n",
    "\n",
    "3. Pooling 2x2 -> 맵의 크기가 절반으로 줄어듬. 채널 영향은 없음\n",
    "\n",
    "(64, 26, 26) -> (64, 13, 13)\n",
    "\n",
    "4. 두 번째 은닉층\n",
    "\n",
    "- 입력되는 채널은 64개 -> 테이터의 채널 수 만큼 필터의 채널 수를 늘림\n",
    "- 합성곱층에 입력되는 데이터 채널 수 에 관계없이 필터 1개당 1개의 채널을 가진 특성 맵을 출력한다. \n",
    "- 두 번째 합성곱층의 필터 크기는 64x3x3 = 576 + 1개 편향 => 필터 1개당 가중치 577개\n",
    "- 필터 수 128개로 지정 => 총 파라미터 개수는 577 * 128 = 73,856\n",
    "- 생성한 맵은 (128, 11, 11)\n",
    "\n",
    "5. 풀링 (11, 11) -> (5.5, 5.5) -> 소수점 버림 -> (128, 5, 5)\n",
    "\n",
    "6. 세 번째 은닉층은 128개 노드를 가진 전결합층 -> 1차원 배열 입력 : 128 * 5 * 5 = 3,200\n",
    "\n",
    "- 입력 데이터는 모든 노드와 연결되므로 입력 3200 * 노드 128 + 편향 128 = 409,728\n",
    "\n",
    "7. 출력층 \n",
    "\n",
    "- 전결합층은 클래스 개수와 같은 10개 노드\n",
    "- 입력 128 * 노드 10 + 편향 10 = 1290\n",
    "\n",
    "### stride\n",
    "\n",
    "유의할 점은 합성곱층에 비해 전결합층에서 가중치가 많아지기 쉽다는 것이다. 전결합층은 입력 데이터가 모든 노드와 연결되기 때문에 입력 데이터의 크기가 조금만 커져도 가중치 수가 급격히 늘어난다. 따라서 전결합층을 사용하기 전에 특성 맵의 크기를 줄여야 하는데, 가중치를 줄이는 방법으로 풀링 외에 스트라이드(stride)가 있다.\n",
    "\n",
    "### 제로 패딩(zero padding)\n",
    "\n",
    "풀링층을 사용하지 않고 스트라이드도 기본값을 두더라도 합성곱층을 거치면서 특성 맵의 크기는 조금씩 줄어든다. 특성 맵의 크기가 계속 작아지면 합성곱층을 많이 배치하지 못하게 된다. 이럴 때는 테두리에 값이 0인 픽셀을 추가해서 원본 이미지의 크기를 키운 후 특성 맵을 도출한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08df029-80ce-42b0-b478-8a8c5fc9ca2b",
   "metadata": {},
   "source": [
    "## 전이 학습(transfer learning)\n",
    "\n",
    "- VGG16 모델이 가진 세 개의 전결합층 중에서 출력층만 새로운 전결합층으로 교체\n",
    "- 합성곱층의 가중치는 수정되지 않도록 고정하고 전결합층의 가중치만 수정해서 모델 학습\n",
    "- datasets 모듈의 ImageFolder 클래스: 폴더 안이 이미지 불러오기\n",
    "- torchvision의 transforms 모듈 : 이미지의 크기나 밝기 등의 데이터 변환 -> 데이터 증강(data augmentation) -> 일반화 성능 높임\n",
    "\n",
    "AdaptiveAvgPool2d(적응형 평균 풀링)\n",
    "\n",
    "- 필터의 크기를 직접 지정하는 것이 평균 풀링이라면\n",
    "- 특성 맵의 크기를 지정해서 지정한 크기의 특성 맵이 생성되도록 피터의 크기를 자동으로 조절하는 것을 적응형 풀링이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dded3f-035c-4f9d-9f99-22fb67d6104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
    "# !unzip cats_and_dogs_filtered.zip data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78165db2-477e-480e-9932-71cc4567eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#############################\n",
    "# 데이터 변환\n",
    "#############################\n",
    "train_config = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                  transforms.RandomHorizontalFlip(),  # 이미지를 무작위로 좌우반전\n",
    "                                  transforms.ToTensor()])\n",
    "\n",
    "test_config = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                  transforms.ToTensor()])\n",
    "\n",
    "# 이미지를 불러와 위 설정을 반영한 데이터세트 자료구조 만들기\n",
    "train_dset = datasets.ImageFolder('data/cats_and_dogs_filtered/train/', train_config)\n",
    "test_dset = datasets.ImageFolder('data/cats_and_dogs_filtered/validation/', test_config)\n",
    "\n",
    "# 한 번에 32개의 데이터 샘플을 배치로 사용하는 데이터로더 생성\n",
    "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 사전 학습 모델인 VGG16 모델 객체 생성 후 가중치 불러옴\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# 모델 구조 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37c62fa9-df81-4f7d-8150-3f3862324c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# 모델의 가중치를 더이상 학습하지 않도록 설정\n",
    "####################################\n",
    "for param in model.features.parameters():\n",
    "    param.require_grad = False\n",
    "    \n",
    "# 출력층을 한 개의 노드를 가진 전결합층으로 교체 -> 마지막 층의 out_features = 1로 변경\n",
    "model.classifier[-1] = nn.Sequential(\n",
    "    nn.Linear(model.classifier[-1].in_features, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(model.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d62a995-735a-4510-9698-6fcde9412518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.712, acc: 0.536, test_loss: 0.622, test_acc: 0.698\n",
      "epoch: 2, loss: 0.572, acc: 0.758, test_loss: 0.492, test_acc: 0.881\n",
      "epoch: 3, loss: 0.428, acc: 0.878, test_loss: 0.334, test_acc: 0.938\n",
      "epoch: 4, loss: 0.274, acc: 0.933, test_loss: 0.196, test_acc: 0.958\n",
      "epoch: 5, loss: 0.175, acc: 0.950, test_loss: 0.126, test_acc: 0.965\n",
      "epoch: 6, loss: 0.118, acc: 0.965, test_loss: 0.093, test_acc: 0.972\n",
      "epoch: 7, loss: 0.092, acc: 0.971, test_loss: 0.075, test_acc: 0.974\n",
      "epoch: 8, loss: 0.080, acc: 0.971, test_loss: 0.066, test_acc: 0.976\n",
      "epoch: 9, loss: 0.065, acc: 0.974, test_loss: 0.065, test_acc: 0.974\n",
      "epoch: 10, loss: 0.061, acc: 0.980, test_loss: 0.055, test_acc: 0.977\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "def train(model, criterion, optimizer, loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model. train()\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1,1)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_predicted = hypothesis >= 0.5\n",
    "        acc = (y_predicted == y_batch).float().mean()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "def evaluate(model, criterion, loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1, 1)\n",
    "            hypothesis = model(X_batch)\n",
    "            loss = criterion(hypothesis, y_batch)\n",
    "            y_predicted = hypothesis >= 0.5\n",
    "            acc = (y_predicted == y_batch).float().mean()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "n_epoch = 10\n",
    "for epoch in range(1, n_epoch+1):\n",
    "    loss, acc = train(model, criterion, optimizer, train_loader)\n",
    "    test_loss, test_acc = evaluate(model, criterion, test_loader)\n",
    "\n",
    "    print('epoch: {}, loss: {:.3f}, acc: {:.3f}, test_loss: {:.3f}, test_acc: {:.3f}'.format(epoch, loss, acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d86bb1-c03d-4140-93f0-3e40a3e54634",
   "metadata": {},
   "source": [
    "## RNN(Recurrent Neural Network, 순환 신경망)\n",
    "\n",
    "- 순서가 중요한 연속적인 데이터 처리에 많이 사용. 언어 번역, 자동 완성, 날씨 예보\n",
    "\n",
    "### 기온, 풍속, 습도 이용해 24시간 뒤의 기온 추론\n",
    "\n",
    "- 입력 데이터는 24시간 동안 3가지 기상 정보가 한 시간 단위로 저장 -> (24, 3)\n",
    "- 타겟은 24시간 뒤의 기온 정보 -> (1,)\n",
    "\n",
    "nn.RNN(특성 개수, 출력할 데이터 특성 수, 첫번째 차원 배치 처리 여부)\n",
    "\n",
    "- 순환 신경망은 첫 번째 차원이 타입 스텝 정보를 나타내는 시퀀스이기 때문에 batch_first=True 하여 배치로 변경\n",
    "\n",
    "cell(X) -> 2개 반환 <br>\n",
    "① 24개의 타입 스텝에 대한 셀의 출력값(24, 3) -> 전결합층에 전달<br>\n",
    "② 마지막 타임 스텝에 대한 셀의 출력값(1, 3) \n",
    "\n",
    "contiguous\n",
    "\n",
    "- batch_first=True로 배치를 첫 번째 차원으로 처리하도록 설정함으로써 셀에 출력된 결과물의 첫 번째 차원이 배치인 것처럼 보이지만 메모리 상에서는 여전히 배치가 두 번째 차원에 존재한다. 이렇게 데이터가 실제로 메모리에 저장된 구조와 차이가 있으면 view 메서드로 데이터의 형태를 변경할 수 없다. 따라서 contiguous 메서드로 배치가 첫 번째 차원인 데이터를 메모리에 새로 만들고, 그 후에 view 메서드로 데이터를 1차원 배열 형태로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852703dd-e331-4ab7-9429-1471aaaa88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import joblib\n",
    "\n",
    "datasets = joblib.load('weather.pickle')\n",
    "\n",
    "data, target = datasets['data'], datasets['target']\n",
    "\n",
    "print('특성과 타겟 데이터 형태:', data.shape, target.shape)\n",
    "print('특성 일부 데이터 보기', data[0])\n",
    "\n",
    "# 학습, 테스트 나누기\n",
    "train_length = 20000\n",
    "X_train, X_test = data[:train_length], data[train_length:]\n",
    "y_train, y_test = target[:train_length], target[train_length:]\n",
    "\n",
    "# 텐서 구조로 변환\n",
    "X_train, X_test = torch.from_numpy(X_train), torch.from_numpy(X_test)\n",
    "y_train, y_test = torch.from_numpy(y_train), torch.from_numpy(y_test)\n",
    "\n",
    "dset_train, dset_test = TensorDataset(X_train, y_train), TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dset_train, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(dset_test, batch_size=256, shuffle=True)\n",
    "\n",
    "#####################\n",
    "# RNN 모델 클래스 정의\n",
    "#####################\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cell = nn.RNN(3, 3, batch_first=True)\n",
    "        self.fc = nn.Linear(24*3, 1) # 최종 기온 1개 노드\n",
    "\n",
    "    def forward(self, X):\n",
    "        out, hidden_state = self.cell(X)\n",
    "        out = out.contiguous()\n",
    "        out = self.fc(out.view(-1, 24*3))\n",
    "        return out\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = RNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "def train(model, criterion, optimizer, loader):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1, 1)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "def evaluate(model, criterion, loader):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1, 1)\n",
    "            hypothesis = model(X_batch)\n",
    "            loss = criterion(hypothesis, y_batch)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train(model, criterion, optimizer, train_loader)\n",
    "    test_loss = evaluate(model, criterion, test_loader)\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print('epoch: {}, loss: {:.3f}, test_loss: {:.3f}'.format(epoch, loss, test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1960403-6450-4321-b62b-4abf8d78755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1, 1)\n",
    "        hypothesis = model(X_batch)\n",
    "        print('predicted target: {:.2f}, real target: {:.2f}'.format(hypothesis[0].item(), y_batch[0].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390cdb65-7d00-4a7d-ab8e-b2203220a3a5",
   "metadata": {},
   "source": [
    "## LSTM(Long Short-Term Memory)\n",
    "\n",
    "RNN도 타임 스텝을 많이 반복하면 기울기 소실 문제 발생. 이를 개선한 모델이 LSTM이다.\n",
    "\n",
    "워드 임베딩(word embedding) : 학습을 통해 밀집 벡터(dense vector)를 얻는 과정. \n",
    "\n",
    "파이토치에서는 단어를 밀집 벡터로 표현하기 위해 임베딩층을 사용한다. 처음에는 모든 단어가 무작위 값을 가지는 밀집 벡터로 표현되고, 학습이 진행되면서 역전파를 통해 점차 밀집 벡터가 모델의 추론 성능에 도움이 되는 값, 즉 단어의 이미를 더 잘 표현하는 값으로 조정된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e2a9e8-41df-4d2a-87b1-fa7118ff6fb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/jun/lazychoi.github.io/review/deep_learning/pytorch_dl.ipynb 셀 68\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jun/lazychoi.github.io/review/deep_learning/pytorch_dl.ipynb#Y124sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m load\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jun/lazychoi.github.io/review/deep_learning/pytorch_dl.ipynb#Y124sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_tokenizer\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jun/lazychoi.github.io/review/deep_learning/pytorch_dl.ipynb#Y124sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvocab\u001b[39;00m \u001b[39mimport\u001b[39;00m vocab\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jun/lazychoi.github.io/review/deep_learning/pytorch_dl.ipynb#Y124sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m IMDB\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "from torch.hub import load\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.datasets import IMDB\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter # 데이터세트에 등장하는 단어들의 출현 빈도\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 학습 세트만 먼저 불러온 이유는 단어장을 만들기 위해\n",
    "train_dataset = IMDB(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "\n",
    "# 학습 세트의 문장을 단어 단위로 토큰화하고 단어별 누적 사용 빈도 계산\n",
    "for label, text in train_dataset:\n",
    "    # 문장을 단어 단위로 토큰화하고 단어별로 사용 빈도 기록\n",
    "    counter.update(tokenizer(text))\n",
    "\n",
    "# 10번 이상 사용된 단어로 단어장을 만든다\n",
    "vocabulary = vocab(counter, min_freq=10)\n",
    "vocabulary.set_default_index(0)  # 단어장에 없는 단어는 0으로 설정\n",
    "\n",
    "# 텍스트를 정수 인코딩하는 람다 함수 정의\n",
    "text_transform = lambda x: [vocabulary[token] for token in tokenizer(x)]\n",
    "\n",
    "# 레이블을 정수값으로 치환하는 람다 함수 정의\n",
    "# pos = 1, neg = 0 으로 치환\n",
    "label_transform = lambda x: 1 if x == 'pos' else 0 \n",
    "\n",
    "# 두 개의 람다 함수를 이용해 텍스트와 레이블을 전처리하는 함수 정의\n",
    "def preprocessing(batch):\n",
    "    label_list, text_list = [], []\n",
    "    # 람다 함수로 배치값을 차례대로 변환\n",
    "    for (_label, _text) in batch:\n",
    "        # 레이블에 람다 함수 적용\n",
    "        label_list.append(label_transform(_label))\n",
    "        # 텍스트에 람다 함수 적용\n",
    "        text_list.append(torch.tensor(text_transform(_text)))\n",
    "\n",
    "    # 정수 인코딩된 데이터 길이는 문장에서 몇 개의 단어가 사용되었는지에 따라 달라지기 때문에\n",
    "    # pad_sequence 함수를 이용해 가장 긴 문장을 기준으로 정수 인코딩된 문장의 길이 통일\n",
    "    # 길이가 가장 긴 데이터를 기준으로 나머지 문장들은 패딩값을 0으로 채워 데이터 길이 통일\n",
    "    data = pad_sequence(text_list)\n",
    "    target = torch.tensor(label_list)\n",
    "    return data, target\n",
    "\n",
    "train_dataset, test_dataset = IMDB(split=('train', 'test'))\n",
    "\n",
    "# preprocessing 함수를 적용하여 학습 세트 데이터로더와 데이터 세트 데이터로더 만듦\n",
    "train_loader = DataLoader(list(train_dataset), batch_size=8, \n",
    "                          shuffle=True, collate_fn=preprocessing)\n",
    "test_loader = DataLoader(list(test_dataset), batch_size=8,\n",
    "                         shuffle=False, collate_fn=preprocessing)\n",
    "\n",
    "# LSTM 모델 클래스 정의\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # 모델 구조 정의\n",
    "        self.embed = nn.Embedding(vocab_size, 16)\n",
    "        self.cell = nn.LSTM(16, 16)\n",
    "        self.fc = nn.Linear(16, 1) # 긍정, 부정 이진분류\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.embed(X)\n",
    "        out, (hidden_state, cell_state) = self.cell(out)\n",
    "        out = self.fc(hidden_state.view(-1, 16))\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "vocab_size = len(vocabulary)\n",
    "model = LSTM(vocab_size).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(model, criterion, optimizer, loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1, 1)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = ((hypothesis >= 0.5) == y_batch).float().mean()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "def evaluate(model, criterion, loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1, 1)\n",
    "            hypothesis = model(X_batch)\n",
    "            loss = criterion(hypothesis, y_batch)\n",
    "            acc = ((hypothesis >= 0.5) == y_batch).float().mean()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "                                                     \n",
    "n_epochs = 25\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss, acc = train(model, criterion, optimizer, train_loader)\n",
    "    test_loss, test_acc = evaluate(model, criterion, test_loader)\n",
    "\n",
    "    print('epoch: {}, loss: {:.3f}, acc: {:.3f}, test_loss: {:.3f}, test_acc: {:.3f}'.format(epoch, loss, acc, test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
