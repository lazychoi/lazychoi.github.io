---
title: 22-11-22(화)
date: 2022-11-22
categories: 2022-11
---

## Word2Vec

1. 위키피디아 한국어 버전 파일 xml
1. wp2txt 사용하여 "xml -> txt" using `wp2txt -i kowiki-latest-pages-articles.xml` (컨테이너를 재실행하여 wp2txt를 인식하지 못할 경우 source ~/.bash_profile 하여 bash를 재실행한다.) m1 맥북에어 20분 정도 소요
1. 423개의 xml 파일과 txt 파일이 만들어짐 -> txt 파일을 하나로 합침 `cat kowiki-latest-*.txt > kowiki.txt`
1. 사용된 단어 추출(형태소 분석) "txt -> wakati" using wiki-wakati.py 반나절 정도 소요
    - 굳이 wakati 파일로 저장할 필요가 없을 것 같다. 그냥 텍스트 문서다. 분해된 형태소가 공백으로 분리되어 있다.
1. word2vec "wakati -> model" using wiki-mkdic.py
    - 입력 형식은 

word2vec 모델 활용

1. from gensim.models import Word2Vec
1. model = Word2Vec.load('wiki.model')
1. 유사어 조사: model.wv.most_similar(positive=['단어', '단어'], negative=['단어', '단어'])
1. 단어 벡터값 확인: model.wv['단어']

## Dockerfile 작성해 도커 이미지 만들기

```Dockerfile
FROM python:3.8
ENV JAVA_HOME /usr/lib/jvm/java-1.7-openjdk/jre
RUN apt-get update && apt-get install -y g++ default-jdk
COPY requirements.txt /root
RUN pip install -r /root/requirements.txt

# Install packages for building ruby
RUN apt-get update
RUN apt-get install -y --force-yes build-essential curl git
RUN apt-get install -y --force-yes zlib1g-dev libssl-dev libreadline-dev libyaml-dev libxml2-dev libxslt-dev
RUN apt-get clean

# Install rbenv and ruby-build
RUN git clone https://github.com/sstephenson/rbenv.git /root/.rbenv
RUN git clone https://github.com/sstephenson/ruby-build.git /root/.rbenv/plugins/ruby-build
RUN /root/.rbenv/plugins/ruby-build/install.sh
ENV PATH /root/.rbenv/bin:$PATH
RUN echo 'eval "$(rbenv init -)"' >> /etc/profile.d/rbenv.sh # or /etc/profile
RUN echo 'eval "$(rbenv init -)"' >> .bashrc

CMD source ~/.bashrc
RUN rbenv install 2.7.6
RUN rbenv global 2.7.6
CMD gem install wp2txt
```

ruby 설치에 애를 먹었다. RUN 에서 에러가 났던 source, gem 명령어가 CMD에서는 에러가 나지 않았다. 

requirements.txt 파일

```text
beautifulsoup4==4.11.1
gensim==4.2.0
JPype1==1.4.1
konlpy==0.6.0
lxml==4.9.1
numpy==1.23.5
pandas==1.5.1
```

도커 이미지 생성 명령어

```bash
docker build --tag text_mining:0.1 .
docker run -it -v ~/chatbot/:/chatbot text_mining:0.1 bash
```

## MLP로 텍스트 분류

- tensorflow 설치: pip install tensorflow
- sklearn 설치: pip install scikit-learn

에러 발생: The file to load file system plugin from does not exist.: '/usr/local/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so  
-> pip install tensorflow_io

에러 발생: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 116082688 exceeds 10% of free system memory.
-> docker Dashboard >> Preferences >> Resources >> Advanced >> Swap 4G로 확장

DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.
-> pip install scikeras[tensorflow]

[scikeras 문서](https://www.adriangb.com/scikeras/stable/notebooks/Basic_Usage.html){target=_blank}

:::{.callout-important}
## 입력 shpae

- MLP : X(2차원), Y(2차원)
- DNN : 1차원 배열
- CNN : 3차원 배열
:::

다중 분류일 경우에는 train 클래스를 원핫인코딩하여 다중 컬럼이 된다. <br>
-> predict 할 때는 argmax(axis=1)을 사용해 가장 큰 값을 뽑아 레이블로 결정한다.

test 클래스는 predict 값이 1열이기 때문에 원핫인코딩을 할 필요 없다.

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation
from scikeras.wrappers import KerasClassifier
from tensorflow.keras.utils import to_categorical 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import json

print('텐서플로 버전: ', tf.__version__)

max_words = 56681
nb_classes = 6 

batch_size = 64 
nb_epoch = 10

# MLP 모델 생성
def build_model():
    model = Sequential()
    model.add(Dense(512, input_dim=max_words))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(nb_classes))
    model.add(Activation('softmax'))
    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['acc'])
    return model

# 데이터 로드
data = json.load(open('./data/data-mini.json'))
# data = json.load(open('./data/data.json'))
X = np.array(data['X']) # 텍스트 데이터
Y = np.array(data['Y']) # 카테고리 데이터 (132,) 2차원 배열

print('X shape: ', X.shape)
print('y 클래스=', np.unique(Y))
print('y shape: ', Y.shape)

# 학습
X_train, X_test, Y_train, Y_test = train_test_split(X, Y)
Y_train = to_categorical(Y_train, nb_classes) # 6열로 원핫 인코딩
print('Y_train shape=', Y_train.shape) # Y_test는 1열 그대로 사용

model = KerasClassifier(model=build_model,
                        epochs=nb_epoch,
                        batch_size=batch_size)
model.fit(X_train, Y_train)

# 예측
pred = model.predict(X_test).argmax(axis=1) # 예측값이 6열로 반환되어 가장 큰 값 1개만 출력
print('pred shape=', pred.shape) 
print('pred[0]=', pred[0])

ac_score = accuracy_score(Y_test, pred)
cl_report = classification_report(Y_test, pred)
print('정답률: ', ac_score)
print('리포트:\n', cl_report)
```

## vim 여러 줄 주석 처리

- 주석 설정: visual 모드로 선택 후 :norm i# -> 삽입모드 후 #
- 주석 해제: visual 모드로 선택 후 :norm 1x -> 1개 문자 삭제
